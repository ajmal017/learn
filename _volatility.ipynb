{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38132bit2115ca79f6634adbad3a74c57c1d7c04",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "\n",
    "Ref: [Calculating centred and non-centred volatility](http://vixandmore.blogspot.com/2009/12/calculating-centered-and-non-centered.html)\n",
    "\n",
    "Stock Volatility measures how much a stock tends to move. There are many ways to calculate volatility, for e.g. through:\n",
    "\n",
    "- Daily/Weekly/Monthly range\n",
    "- Average True Range\n",
    "- Standard Deviation\n",
    "\n",
    "Standard Deviation is the most popular way to measure volatility. Standard Deviation for stock price can be computed in multiple ways. Let us go through them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# computing SD of a series of values\n",
    "data = [161.47, 159.86, 159.27, 159.98, 159.78, 157.21, 157.5, 157.86, 160.95, 161.6, 159.85, \n",
    "         157.48, 155.32, 160.43, 159.45, 158.19, 155.78, 154.96, 156.53, 149.46, 148.15] # gives sd of 1.59%\n",
    "\n",
    "s = pd.Series(data, name='data')\n",
    "df = pd.DataFrame(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) From math library's standard deviation computation.\n",
    "\n",
    "The code for this is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'asd': 3.533283849608569, 'amean': 157.67047619047622}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = df.data.std()\n",
    "amean = df.data.mean()\n",
    "dict(asd=asd, amean=amean)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arithmetic standard deviation makes sense for a stable mean. However, in stock prices the price keeps current price keeps changing. So it is better to use **geometric standard deviation** or GSD. \n",
    "\n",
    "Here are different ways of getting GSD:\n",
    "\n",
    "## 2a) From daily log returns assuming zero mean and averaging squares\n",
    "Ref: [this Quora link](https://www.quora.com/How-do-you-calculate-the-standard-deviation-for-a-stock)\n",
    "\n",
    "Formula for geometric standard deviation is represented by:\n",
    "     \n",
    "gsd1 = $\\exp{\\Big(\\sqrt{{\\frac{\\sum_{1}^n (\\ln\\frac{x[n]}{x[n-1]})^{2}}{n}}}}\\Big)$\n",
    "\n",
    "Geometric standard deviation is computed over geometric mean, which is represented by the formula:\n",
    "\n",
    "gm = $\\left (\\prod_{a=1}^{b}x_i  \\right )^{\\frac{1}{n}} = \\sqrt[n]{x_1x_2...x_n}$\n",
    "\n",
    "The upper and lower values of 1 GSD are computed by dividing and multiplying geometric mean with the geometric standard deviation\n",
    "\n",
    "The code for these are as follows:\n",
    "\n",
    "```\n",
    "import math\n",
    "from scipy.stats.mstats import gmean\n",
    "sdmult = 2 # no of standard deviations\n",
    "gsd1 = math.exp(math.sqrt(df.data.rolling(2).apply(lambda x: math.log(x[0]/x[-1])**2, raw=True).mean()))\n",
    "gm = gmean(df)\n",
    "glo1 = gm*(1-(gm-gm/gsd1)/gm*sdmult) # gm/gsd1 ... but taking sdmult into consideration\n",
    "ghi1 = gm*(1+(gm*gsd1-gm)/gm*sdmult) # gm*gsd1 ... but taking sdmult into consideration\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'gm': array([157.63194626]),\n 'gsd1': 1.0160309183814213,\n 'glo1': array([152.65771798]),\n 'ghi1': array([162.68591599])}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from scipy.stats.mstats import gmean\n",
    "sdmult = 2 # no of standard deviations\n",
    "gsd1 = math.exp(math.sqrt(df.data.rolling(2).apply(lambda x: math.log(x[0]/x[-1])**2, raw=True).mean()))\n",
    "gm = gmean(df)\n",
    "glo1 = gm*(1-(gm-gm/gsd1)/gm*sdmult) # gm/gsd1 ... but taking sdmult into consideration\n",
    "ghi1 = gm*(1+(gm*gsd1-gm)/gm*sdmult) # gm*gsd1 ... but taking sdmult into consideration\n",
    "\n",
    "dict(gm=gm, gsd1=gsd1, glo1=glo1, ghi1=ghi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2b) From daily log returns without squaring and square-rooting\n",
    "\n",
    "The formula for this is:\n",
    "\n",
    "sd2 = ${\\exp(\\sigma\\Big({{\\ln(\\frac{x[n]}{x[n-1]})}}\\Big))}$\n",
    "\n",
    "This equation gives a slightly lesser band than taking rooting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'gm': array([157.63194626]),\n 'gsd2': 1.015831867370207,\n 'glo2': array([152.71851886]),\n 'ghi2': array([162.62316239])}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from scipy.stats.mstats import gmean\n",
    "sdmult = 2 # no of standard deviations\n",
    "gsd2 = math.exp(df.data.rolling(2).apply(lambda x: math.log(x[0]/x[-1]), raw=True).std())\n",
    "glo2 = gm*(1-(gm-gm/gsd2)/gm*sdmult) # gm/gsd2 ... but taking sdmult into consideration\n",
    "ghi2 = gm*(1+(gm*gsd2-gm)/gm*sdmult) # gm*gsd2 ... but taking sdmult into consideration\n",
    "\n",
    "dict(gm=gm, gsd2=gsd2, glo2=glo2, ghi2=ghi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c) Centred Historical Volatiity using look-back\n",
    "\n",
    "[This is the most preferred approach](http://vixandmore.blogspot.com/2009/12/calculating-centered-and-non-centered.html) of using SD for volatility. The steps are as follows:\n",
    "\n",
    "1. Select a desired lookback period in trading days (lookback period)\n",
    "2. Gather closing prices for the full lookback period, plus one additional day (lookback +1)\n",
    "4. Calculate the daily close-to-close price changes in a security for each day in the lookback period (daily change)\n",
    "5. Determine the natural log of each daily percentage change (log of daily changes)\n",
    "6. Calculate the mean of all the natural logs of the closing prices for the lookback period (log lookback mean)\n",
    "7. For each day, subtract the lookback mean from the log of daily changes (daily difference)\n",
    "8. Square all the differences between the mean and the daily change (daily variance)\n",
    "9. Sum all the squares of the differences (sum of variances)\n",
    "10. Divide the sum of the squares of the variances by the lookback period (lookback variance)\n",
    "11. Take the square root of the lookback variance (historical volatility, expressed as a standard deviation)\n",
    "12. Compute the high and low bands for the lookback period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}